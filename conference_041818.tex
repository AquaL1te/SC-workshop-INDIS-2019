\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{footnote}
\usepackage{multicol}
\usepackage{float}
\usepackage{url}[hyphens]
\usepackage[acronym, nonumberlist]{glossaries}

\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{Sharing digital objects across different data infrastructures using Information Centric Networking
}

\author{\IEEEauthorblockN{Kees de Jong, Cas Fahrenfort, Anas Younis, Zhiming Zhao*}
\IEEEauthorblockA{\textit{System and engineering lab} \\
\textit{University of Amsterdam}\\
Amsterdam, the Netherlands \\
kees.dejong@os3.nl, casfahrenfort@live.nl, anas.younis@os3.nl, z.zhao@uva.nl}
}

\maketitle

\begin{abstract}
Data infrastructures manage data assets across and allow users to efficiently discover and assess data. To make their assets findable, accessible, interoperable, and reusable (namely FAIR), data infrastructures need to provide data assets not only rich meta information for describe its semantics and contextual information, but also globally resolvable identifiers. The \glspl{pid}, like digital object identifier (DOI) are often used by data publishers and infrastructures. The traditional IP network approach and client-server model for data access can potentially cause congestion and delays with many data consumers. In contract, the Information Centric Networking (ICN) such as \gls{ndn} adopts a data centric approach where data objects, once requested, may be stored on intermediate hops in the network. Consecutive requests for that unique digital object are then made available by these intermediate hops (caching). This approach distributes traffic load more efficient and reliable compared to host-to-host connection oriented techniques, and demonstrates attractive opportunities for sharing digital objects across distributed network. However, such approach also face several challenges. It require not only effective translation between the different naming schemas among \gls{pid} and \gls{ndn}, in particular for supporting PID from different publishers or repositories. Moreover, the planning and configuring an ICN environment for distributed infrastructure is lack of automated solution. To bridge the gap, we proposes an ICN planning service with specific consideration of interoperability across \gls{pid} schemas in the Cloud environment.
%Data infrastructures manage data across their lifecycle, and provide them  of massive data, and provide them, this data is published by the use of \glspl{pid}. The traditional network approach for data transmissions are done with host-to-host connections (IP), where every data request from the consumer is answered with a data transfer from the source (the producer). This approach can potentially cause congestion and delays with many data consumers. \gls{ndn} is a data centric approach where unique data, once requested, may be stored on intermediate hops in the network. Consecutive requests for that unique digital object are then made available by these intermediate hops (caching). This approach distributes traffic load more efficient and reliable compared to host-to-host connection oriented techniques.

%The \glspl{pid} are used by data providers within these data infrastructures for sharing and identifying digital objects. In order to create \gls{pid} and \gls{ndn} integration, a translation between the different naming schemas is needed. This paper proposes a solution for accessing and sharing digital objects with different \gls{pid} schemas over a networked environment using \gls{doip} and \gls{ndn}. Furthermore, a solution is proposed to plan and deploy an \gls{ndn} with a scalable method for Cloud environments.



\end{abstract}

\begin{IEEEkeywords}
Named Data Networking, Persistent Identifier, Digital Object Interface Protocol, FAIRness, Network Functions Virtualization
\end{IEEEkeywords}

\section{Introduction}
In many scientific domains, massive data collected from observations, simulations and system logs, become important assets for enabling further data centric sciences e.g., modelling complex environment problem requires a long history of observation data \cite{}. After careful curation, data become an important asset in data infrastructures. Typical examples include ocean observation data in EuroArgo\footnote{\url{https://www.euro-argo.eu/}} and SeaDataNet\footnote{\url{https://www.seadatanet.org/}}, air monitoring data in the \gls{icos} research infrastructure\footnote{\url{https://www.icos-ri.eu/}} and \gls{actris}\footnote{\url{https://www.actris.eu/}}, and solid earth monitoring in \gls{epos}\footnote{\url{https://www.epos-ip.org/}}. Those continuously growing data from different research infrastructures provide valuable input from different domains, and can significantly enhance the feasibility for doing research at the system level, e.g., for studying climate change and natural disasters. However, users still have to face several challenges to effectively discover and utilise those assets.

The limited \gls{fairness} of digital assets prevents users from effectively discovering digital assets from distributed sources and obtaining their content for specific purposes. It becomes a common challenge for many research infrastructures to improve \gls{fairness}; \gls{envri} is such an effort, recently funded for improving the \gls{fairness} for more than 10 environmental research infrastructures. The globally resolvable identifier (also called (\gls{pid})) of digital objects and their rich contextual metadata are often highlighted as important aspects when improving the \gls{fairness}, as recommended in the 11 principle of \gls{fairness} \cite{}. There are already quite some research infrastructures that have already adopted \gls{doi} or other types of \gls{pid} solutions for publishing their digital objects, e.g., in \gls{icos}.

Moreover, the classical client-server or P2P solutions for sharing and distributing digital objects has to face the challenges of heterogeneous repositories cross infrastructures, diverse granularity of digital objects, and continuously growing scale of the data quantity, sources and involved users. The \gls{eosc} is moving towards the direction of providing an open ecosystems for different parties to effectively share their services and data, and to utilise them in the life cycle of their research activities. Protocols like the \gls{doip} have also been recommended by the community of \gls{rda} to handle the sharing of digital objects. However, it is still challenging to share data with heterogeneous sizes and \glspl{pid} among the different infrastructure.

On the other hand, the networking technologies have made big progresses during the past years for improving the distribution efficiency, e.g., \gls{icn} \cite{zhang2014named}, customizability for specific application purpose, e.g., \gls{sdn} \cite{kreutz2014software}, and effectively resource management and sharing over common network infrastructures, e.g., \gls{nfv} \cite{han2015network}. Those advanced technologies still lack seamless support for being embedded in the data management life cycle, e.g., for discovering and sharing digital objects with \glspl{pid}. In the earlier papers \cite{koulouzis2018information}, Koulouzis et al. discussed the feasibility to use \gls{icn} solution like \gls{ndn} to distribute the digital object with \glspl{pid}; however, the work only focuses on the \glspl{pid} form a single publisher. Cloud caching \cite{} and data lake \cite{} are other types of solution focus on smart caching of the digital object across distributed infrastructures, but did not have an explicit model of the data contents global resolvable identifiers.

In this paper, we extend our earlier work of \gls{naas4pid} \cite{koulouzis2018information}, and specifically look at three aspects in applying \gls{ndn} in data infrastructures: 1) how to seamless publish version controlled digital objects with \gls{pid}, 2) how to plan a customized virtual \gls{ndn} environment for user community of a different infrastructures, and 3) how to distribute digital objects from distributed data sources with heterogeneous \gls{pid} publishers. We will use a case study from the SeaDataCloud and structure the paper in five parts. First we will briefly introduce the pilot use case, and review the state of the art and related work. And then we will present the proposed solution XXXX, after that we will explain the detailed design and prototype of the solution, and demonstrate its usage via the use case.



%This paper is divided into two parts. Section \ref{pid-interoperability} explores solutions to translate \glspl{pid} into \gls{ndn} compatible names. And section \ref{ndn-planning-deployment} explores solution to plan and deploy \gls{ndn} with scalability in mind.

\section{Problem background, challenges and related work}
\subsection{Background}
Information technologies, e.g., sensor networks, databases and Cloud computing, have been used to develop the management facilitate of research data from acquisition, quality control, storage, to discovery and processing. Data infrastructures \cite{} manage the data assets across the entire life cycle, and provide services for end users or applications to discover, access and utilise data for specific application purposes. Some research infrastructures that only focus on the assets of data, can also be seen as data infrastructures \cite{}. 

In the environmental and earth sciences, there are more than 20 research infrastructures being developed from different sub-domains, like marine, atmosphere, solid earth and ecosystem. In those infrastructures, important digital assets include observations, measurements and collections. A typical example can be seen from the marine data infrastructure SeaDataNet. It is an infrastructure that aggregates a number of oceanography data sources, publish their metadata and provide a Cloud based sharing facilitate for distributed user community, as shown in figure \ref{fig:sdc_cur}. 
\begin{figure}[H]
\centering
\includegraphics[width=\columnwidth]{images/SDC_current.png}
\caption{SeaDataNet's current infrastructure.}
\label{fig:sdc_cur}
\end{figure}

The scale of a data infrastructure often evolves when the deployment of the acquisition sensors increases, or the number of the service users grows. To deliver high quality services to the user community, the SeaDataNet infrastructure has to face several challenges:
\begin{enumerate}
    \item Fault tolerance challenges. The SeaDataNet originally only gathers metadata from remote repositories, and the user has to access the individual remote repository to obtain data. Such client-server style not only creates high load for the repository but also network traffic congestion.
    \item Performance challenges. A Cloud cache solution has been proposed in SeaDataNet to duplicate each remote repository a copy in Cloud, In this way, the clients can direct retrieve the copy of data assets from the Cloud server. However, such solution also needs careful customization for load-balancing and service placement to keep the performance high.
    \item Scalability challenges. The SeaDataCloud has to face the continuous growth of both data providers and the user community. In many cases, geo special data retrieval needs calculation of the region, layers and the time duration. The system has to face scalability challenges of both network and the server capacity. 
\end{enumerate}
In the rest of the section, we will review the related work of these topics and discuss the key contributions of our work. 
\subsection{FAIR Principles}

The FAIR principles \cite{fair} \cite{wilkinson2016fair} are guiding principles for scientific data management and stewardship, intended to make data sets more Findable, Accessible, Interoperable and Re-usable. They emphasize machine-actionability since researchers are increasingly more reliant on computational support when dealing with data due to the constant increases in size, amount and creation speed.

To be \textit{Findable}, (meta)data should be assigned a globally unique and persistent identifier and be indexed in a searchable resource.

To be \textit{Accessible}, (meta)data should be accessible using a standardised communications protocol, so the users know how they can be accessed (including any possible authentication/authorisation).

To be \textit{Interoperable}, (meta)data should use a formal, accessible, shared and broadly applicable language for knowledge representation, to be able to interoperate with applications/workflows for analysis, storage and processing.

To be \textit{Re-usable}, (meta)data should be richly described with a plurality of accurate and relevant attributes so they can be replicated and/or combined in different settings. 

Contrary to popular belief, FAIRness does not imply actual fairness (without favoritism or discrimination) of data. FAIR data is not necessarily openly accessible and/or usable by everyone. FAIRness in this context only refers to the \textit{methods} used for accessibility and usability, on top of which additional authentication or authorization might be required.

\subsection{Persistent Identifiers (PIDs)}
\label{sec:pids}

Persistent Identifiers are in essence a permanent reference to a document, file, web page or other object. Generally, a persistent identifier is assigned to a data object on request of the client, after which the service guarantees that whenever this identifier is resolved, it will provide some information about the object. It does not guarantee the object will be available forever, as the object might be deleted due to e.g. data management costs. However, if the object is deleted, the identifier should still be resolvable (to what is known as a "tombstone page"). Information about the data set can still be learned from this resolution, such as provenance, contextual information, possible redirection to updated version and reason for deletion.

PIDs often have different "namespaces" which can be used to point to different sub-resolvers, much like how URLs can have different sub-domains. These namespaces can be used to allow a single resolver to resolve multiple top-level PIDs to a number of distinct resolvers which have their own PID resolution system and separate repositories for storing data. This structure allows multiple different organizations to resolve data using a single PID scheme, as long as they agree to uphold the persistence policies set by the top-level resolver.

There are currently a number of well known PID schemes, each using a different approach and structure \cite{workpackage6}:

\begin{itemize}
    \item \textbf{The Handle System (HS)} One of the earliest created PID systems, providing governance for top-level namespaces. However, besides this it does not provide any obligations with respect to persistence policies
    \item \textbf{Digital Object Identifier (DOI)} One of the most well-known PID systems due to its usage for citing scholarly literature. It makes use of the Handle System and uses its namespace "10.[subnamespace]/"
    \item \textbf{Uniform Resource Name (URN)} Unlike the Handle System, URNs do not use a common resolver system. Therefore it is up to the user to know which resolver system to use, which has been a severe impediment against the uptake of this system
    \item \textbf{Persistent URL (PURL)} PURL does not separate between identifier and resolving mechanism, and has no single global resolving mechanism. 
    \item \textbf{Archival Resource Key (ARK)} Initially, ARK was planned to enable decentralised resolvers. However, ARK now relies on local resolvers which ARK-issuing archives have to provide and maintain.
\end{itemize}

\subsection{PID Providers}

There are several services which provide the creation of a variety of different persistent identifiers. Some of the most notable are:

\begin{itemize}
    \item \textbf{The European Persistent Identifier Consortium (ePIC)} Based on Handles, ePIC PIDs can be used for any data objects and data collections. Consortium members share services and APIs, meaning that if one center is out of order, other centers can still resolve and distribute PIDs \cite{workpackage6}.
    \item \textbf{DataCite} A non-profit, community-driven organisation that provides DOI services for research data, including generation and allocation of DOIs and related metadata, and discovery services for research data. 
    \todo{ORCID, ISNI(?)}
\end{itemize}

\subsection{Digital Objects (DOs)}
\label{sec:digital_objects}

Digital Objects are defined as "meaningful entities", meaning that they contain data which people want to talk about, work with, process, refer to, cite etc. The motivation for defining these DOs was to give messages exchanged between repositories and processing units meaning, which can be interpreted by both humans and machines \cite{wittenburg2019persistent}.

The RDA Data Foundation \& Terminology Group defined the notion of a Digital Object in 2014, moving a step ahead of the FAIR principles by defining a model of how the different entities described in them need to be related \cite{wittenburg2019persistent}. Shown in Figure \ref{fig:do}, a Digital Object is represented by a structured bit sequence (data) being stored in a repository, is referenced by a PID and described by metadata. 

\subsection{Digital Object Interface Protocol (DOIP)}
\label{sec:doip}

The DOIP \cite{dona2018digital} is a core protocol of the DOA, a logical extension of the Internet architecture that addresses the need to support information management more generally than just conveying information in digital form from one location to another, enabling interoperability across heterogeneous information systems. The DOA specifies two core protocols for communication and three system components for managing Digital Objects:

The \textbf{Identifier/Resolution Protocol (IRP)} is used for creating, updating, deleting and resolving DO identifiers. Each identifier is of the form prefix/suffix and is associated with an identifier record containing relevant "state information" clients can resolve to. The identifier's prefix is resolved to locate the specific identifier/resolution service to be used (the suffix may be any bit sequence). An organization may run their own resolution system by having a prefix allotted to it.

The \textbf{Digital Object Interface Protocol (DOIP)} specifies a standard way for clients to interact with DOs. The DOIP makes use of the IRP for associating identifiers with different elements of the protocol. DOIP enables the provision of security by validating digital objects as well as ensuring integrity via signatures. Basic operation clients may invoke on the DO services are defined; addition of operations is supported. Each DO must specify its type (which is extensible), enabling DOIP services to identify allowable operations. Each type is associated with an identifier record that can be accessed by use of the IRP.

The \textbf{Identifier/Resolution System} provides the following services:
\begin{itemize}
    \item allotment of unique identifiers to information structured as digital objects
    \item rapid resolution of identifiers to current state information of the digital object
    \item administration of the identifier records containing state information
\end{itemize}

The \textbf{Repository System} provides provision of access to digital objects based on identifiers (integrated security), as well as abstracting away the details of storage technologies from the client, enabling long-lived mechanism for depositing and accessing digital objects.

The \textbf{Registry System} stores metadata about digital objects which are managed by repository systems.

From a data consumer perspective, these systems and protocols combine into a single, virtualized layer on top of existing data storage systems, known as the Global Digital Object Cloud (Figure \ref{fig:gdoc}). Consumers only interact with logical representations of DOs and any organizational complexity is hidden away \cite{wittenburg2019persistent}.

\subsection{DOIP and PID}
Cordra \cite{cordra} is an open-source Digital Object Management application, a core part of the Digital Object Architecture (DOA) \cite{sharp2016overview}. It offers functionality for creating, editing and accessing digital objects as discrete data structures with unique, resolvable identifiers. Metadata is automatically extracted from any digital information (documents, images, spreadsheet data etc.) included in the objects and users may generate additional metadata themselves.

In essence, it allows you to create a repository of digital objects and expose it over the Internet. Any object you create is allotted a persistent identifier (PID), which can be resolved using the Handle registry \cite{handle} \cite{sun2003handle}. A REST API is provided over HTTP and a DOIP \cite{dona2018digital} interface over TCP enabling machine-to-machine communication. A web interface is provided through which users can access and manipulate the digital objects, and access control policies can be set to govern who can perform what actions. DOs can be versioned by the users, which creates an identical copy of the DO, with a reference to the previous version. 
\subsection{Named Data Networking research}
\gls{ndn} is not yet implemented on a large scale, with the exception of several large testbeds. In order to plan an \gls{ndn}, it would be necessary to know what works and does not work. However, there is sufficient research available that focused on particular design choices of \gls{ndn}. Research done by Lim et al. at a large existing testbed located in the USA highlighted a few lessons learned \cite{lim2018ndn}. Lim et al. setup the first intercontinental \gls{ndn} testbed with the intent to see the benefits for big science. They concluded that \gls{ndn} provided performance improvements compared to classical climate data delivery techniques based on TCP/IP. \gls{ndn} over TCP demonstrated a more reliable and faster performance compared to UDP. This was due to the allowance of larger dynamic window sizes and congestion control in TCP. Native \gls{ndn} congestion control is still an open research area \cite{ren2016congestion}, as of writing this paper, no proposal has been implemented.

The performance benefits of \gls{ndn} concluded by Lim et al. correlates with research done by Shannigrahi et al. at the USA-based large hadron collider network \cite{shannigrahi2015named}. The researchers achieved a 71\% reduction in the average delay per data chunk compared to a no-caching case. They conducted \gls{ndn} caching simulations \cite{shannigrahi2017request}, where they concluded that a small cache of several gigabytes reduces the network load. However, as expected, increasing the cache towards 1TB reduced the network load even further. However, this reduction of load was not proportional to the cache size. They concluded in their research that a 1GB \gls{ndn} cache at the edge of the \gls{ndn} can already significantly improve data distribution and reduce the network load. The average file size in use was 1.3GB.

Furthermore, in \gls{ndn} several caching, cache replacement and forwarding strategies can be used to fine-tune performance. Koulouzis et al. researched these strategies and concluded that the `leave copy everywhere' caching strategy provided the best performance ratio between cache size to digital object size for generic data usage \cite{koulouzis2018information}. However, `leave copy down' and `leaving copies with probability' performed best for delivering big data objects. Koulouzis et al. also concluded that the ascending ordering of digital objects enhances network performance when combined with the `least recently used' caching strategy. This was concluded based on observations that if large digital objects were requested first, the cache replacement algorithm would make room by overwriting files already in the cache, resulting in cache misses. When small files were requested first, more cache hits were measured. As for cache size, the researchers recommended a cache size at least twice the size of the biggest digital object in the network \cite{koulouzis2018information}.

Yuan et al. researched the performance of \gls{ndn} forwarding \cite{yuan2012scalable}. They used the \gls{ccnx} application\footnote{\url{https://wiki.fd.io/view/Cicn}} to perform experiments. Their research concluded that packets with long names degraded performance. After profiling the software they measured that the \gls{ndn} name decode operation took 35.46\% of the entire program running time. So et al. developed a method to achieve fixed lookup times with variable length names \cite{so2013named}. In order to achieve this goal they explored the application of hash tables to do name lookup. Furthermore, they explored the possibility to do this in hardware by using a Cisco ASR9000 router with the integrated service module running 64-bit Linux. With their experiments they managed to forward 20Gbps of real \gls{ndn} traffic. Tortelli et al. researched the effectiveness of two opposite forward strategies; flooding and best-route (with and without caching) \cite{tortelli2013performance}. Several experiments lead them to the conclusion that there are pros and cons in each forwarding strategy. But that it is difficult to determine the best performing forward strategy.


%Research Clouds such as proposed in the \gls{eosc} will offer Europe's 1.7 million researchers and 70 million science and technology professionals the means to store, share and re-use large volumes of information generated by the big data revolution. Research Clouds publish datasets from distributed sources, identified by a \gls{pid}. These datasets are not accessed via e.g. a simple web portal like traditional internet digital objects on the web. Instead these requests are processed by e.g. a data catalog of the federated research Cloud. Therefore, research Clouds face the challenge of identifying distributed data in a federated Cloud, provide data provenance and provide a scalable service to serve many users that request large datasets.

% This part is already discussed in the new introduction part by Zhiming
% Furthermore, research Clouds face a trend of increased data production and consumption, which is expected to grow. This general trend in research Clouds calls for a data distribution solution that better supports the scale and complexity. An example of such a research Cloud is SeaDataNet, which is a distributed marine data infrastructure network for managing the large and diverse data sets collected by the oceanographic fleets and the automatic observation systems. Their aim is to advance and increase the usage of SeaDataNet's services by adopting Cloud and high performance computing technology for better performance.

%Introducing the architecture in figure \ref{fig:sdc_cur} into an NDN is not solved yet. Multiple data providers need to be hosted, which potentially use different \gls{pid} schemas. \gls{naas4pid} is an extension of \gls{ndn} which allows it to interoperate with \glspl{pid} and is used by SeaDataNet. \gls{naas4pid} adds an additional system layer which translates \glspl{pid} to \gls{ndn} names and optimizes and manages the virtual \gls{ndn} overlay in Cloud or other e-infrastructures. However, \gls{naas4pid} currently only supports a single \gls{pid} provider.

\subsection{PID interoperability research}
In 2014, Karakannas researched the efficiency of \gls{icn} for delivering big data with \glspl{pid} \cite{icn-bd}. The research proposed a mapping architecture for resolving \glspl{pid} to \gls{icn} names. Karakannas proposed to use a \gls{pid} to \gls{ndn} mapping server for every \gls{pid} type instead of implementing the translation on the clients browser.

In 2017, Mousa researched the fetching and sharing of \gls{doi} objects with \gls{icn} such as \gls{ndn}. The researcher's approach focused only on \gls{doi} digital objects within \glspl{ndn}. The researcher explained that the difference in \gls{ndn} naming of different \gls{pid} providers must be taken into account, such that the correct prefix is used within \gls{ndn} to identify specific \gls{pid} types. In the researcher's design, the translation happens in the consumers browsers. The consumer has the choice to either request the digital object by its \gls{ndn} name or \gls{pid} \cite{ndn-app-aware}.

Zhao et al. continued the research done by Karakannas \cite{icn-bd} and Mousa \cite{ndn-app-aware} and proposed an architecture to map \glspl{pid} into the naming schema of \gls{ndn}. Their proposed solution is named \gls{naas4pid}. This solution is composed out of three key components \cite{koulouzis2018information}:
\begin{itemize}
  \item \gls{pid}2\gls{ndn} gateway.
  \begin{itemize}
        \item Primarily responsible for resolving \glspl{pid} to \gls{ndn} names.
  \end{itemize}
  \item \gls{ndn}4\gls{pid} router image.
    \begin{itemize}
        \item An \gls{ndn} node that implements a virtualized \gls{ndn} router.
    \end{itemize}
  \item \gls{ndn}4\gls{pid} manager.
    \begin{itemize}
        \item Automates the management of the \gls{ndn} overlay in\newline Cloud or e-infrastructure.
    \end{itemize}
\end{itemize}
\subsection{Key contributions}
In this paper, we will bring the follow three contributions:
\begin{enumerate}
    \item Propose a PID object publishing plugin for the data management lifecycle; 
    \item Propose a NDN planner for setting virtual NDN envioronment.
    \item Develop a PID interoperability service for handling different PID schemas. 
\end{enumerate}


\section{Proposed solution}

\section{PID and NDN interoperability with version control}
\label{pid-interoperability}

\gls{fairness} is crucial for enabling open science and innovation based on digital objects (\glspl{pid}) from large communities of providers and users. However, the gaps among version control, identification and distributed access systems often make the scalability of data centric applications difficult across large user communities and highly distributed infrastructures. This section proposes a solution for accessing and sharing digital objects over a networked environment using \gls{doip} and \gls{ndn} by the use of \gls{naas4pid}. Furthermore, a \gls{pid} to \gls{ndn} translation prototype will be discussed with extensible support for \gls{pid} types in mind.

\subsubsection{A DOIP centered versioning, publishing and distributing data management solution}
To seamlessly integrate the management services for versioning control, publishing, discovery and distribution of digital objects, globally resolvable and persistent identifiers of the digital objects are crucial. Moreover, the data infrastructure must 1) facilitate data discovery and identification, 2) guarantee available metadata for all digital objects and 3) support resolution of persistently identified data. Furthermore, the distribution system should 1) have reasonable performance, 2) be scalable with the amount of traffic occurring on the network and 3) be easily integratable for both organizations and consumers with legacy systems. Lots of existing data management systems have originated from early legacy systems, e.g., environmental observation stations, and lack a global data identifier centered design for data services.

\gls{naas4pid} is an extension of \gls{ndn} which allows it to interoperate with \glspl{pid}. \gls{naas4pid} adds an additional system layer which translates \glspl{pid} to \gls{ndn} names and optimizes and manages the virtual \gls{ndn} overlay in Cloud or other e-infrastructures. In the architecture as shown in figure \ref{fig:sdc_cur}, only a single data provider is present on the network, since \gls{naas4pid} can currently only support one provider. Additional content providers could offer large community benefits, such as third parties independently creating education material.

\begin{figure}[h]
\centering
\caption{A DOIP centered architecture for digital object version control, publishing and distribution}
\label{fig:architecture}
\includegraphics[width=0.4\textwidth]{images/architecture.png}
\end{figure}
\subsection{Technical considerations}

\ref{fig:architecture} shows a preliminary architecture for persistently publishing digital objects from an organization’s legacy system. Following from the workflow in figure \ref{fig:sequence}, it is divided into three distinct parts: version control system, data publication and data distribution. Content created by community content providers is processed and stored (in its internal repository) by the version control system in any form that is required by its specific use case. Once submitted content has been approved, it is published to persistent data and metadata repositories by any \gls{pid} system. From there, the data can be discovered and accessed by content consumers through the \gls{ndn} by the use of the \gls{naas4pid} service.

\begin{figure}[h]
\centering
\caption{Data processing in an open education platform}
\label{fig:sequence}
\includegraphics[width=0.4\textwidth]{images/sequence.png}
\end{figure}

This architecture is generic in the sense that any existing legacy system can adopt it. The system only needs to be expanded with functionality to publish the data to the PID system, including a mapping between existing data structure and a (meta)data structure fitting to the PID system.

\subsubsection{Extensible PID and NDN interoperability}
\label{interoperablity}
In this section, we will discuss an \gls{ndn} to \gls{pid} interoperability prototype with \gls{pid} extensibility in mind. Our design is based on related work done by Karakannas \cite{icn-bd}, by avoiding the \gls{pid} to \gls{ndn} translation on client side \cite{icn-bd}. The pattern matching method was based on related work by Mousa for identifying different \gls{pid} types \cite{ndn-app-aware}. The research done by Olschanowsky et al. was used for deriving \gls{ndn} names from metadata \cite{ndn-man}.

Our prototype design consists of the following components, each with their own functionality; the \gls{pid} server, the \gls{pid} to \gls{ndn} gateway and the client. The general idea is that a user enters a \gls{pid} of the digital object that the user wants to retrieve at the client and gets back the requested digital object. The retrieval of a digital object depends if is already published in the \gls{ndn} or not. The \gls{pid} to \gls{ndn} gateway implements the translation of different \gls{pid} types and sends the translated name back to the client. Furthermore, we identify \gls{pid} types based on pattern matching as described by Mousa \cite{ndn-app-aware}.

The gateway is responsible for translating a \gls{pid} to \gls{ndn} name and checks if the requested digital object is already published in \gls{ndn}. The first responsibility is translating the \gls{pid} it receives from the client to an \gls{ndn} compatible name. In our prototype we implemented the Handle \gls{pid} type within our \gls{pid} server. Furthermore, we also implemented the URN \gls{pid} type of the national library of the Netherlands, as well as the \gls{doi} type of PANGAEA. Based on pattern matching of the \gls{pid} type\footnote{\url{https://github.com/AquaL1te/rp2/blob/master/Scripts/pid_server.py#L58-L62}}, the gateway detects what kind of \gls{pid} type it has to process. Then, the associated function in the code is called to translate the \gls{pid} to \gls{ndn} name and appends the corresponding link of the web resolver of the \gls{pid} type it receives\footnote{\url{https://github.com/AquaL1te/rp2/blob/master/Scripts/pid_server.py#L17-L37}}. The patterns of most standardized \gls{pid} types are documented in the ePIC \gls{dtr}\footnote{\url{http://dtr-test.pidconsortium.eu}}.

Furthermore, the second responsibility of the gateway is to check if the digital object is already published in \gls{ndn}. If the digital object is available in \gls{ndn}, the gateway sends the translated \gls{ndn} name back to the client. The client then retrieves the digital object from \gls{ndn}. If the digital object is not available in \gls{ndn}, then the gateway sends back the \gls{pid} link to the client and caches the digital object in \gls{ndn} for future requests.

\gls{pid} metadata can be used to substitute missing fields in the \gls{pid} URN in order to create an \gls{ndn} compatible hierarchical name. Therefore, if metadata is used, a parser has to be implemented in the gateway. The \gls{ndn} namespace is unbounded. However, using long \gls{ndn} names could degrade performance with many data consumers, as described by Yuan et al. \cite{yuan2012scalable}.

\section{Planning and deploying an NDN}
\label{ndn-planning-deployment}
An \gls{ndn} is typically distributed geographically. Therefore, deploying \gls{ndn} on Cloud providers helps distribution. However, Cloud providers lack standardization and offer different interfaces to orchestrate resources and maintain the life cycle of services. This section explores the methods involved to plan and deploy \gls{ndn}.

\subsection{Planning}

\subsubsection{McCabe}
Scalability is defined as capacity to be changed in size or scale. In order to plan an \gls{ndn} with this goal in mind we used McCabe's method. McCabe's book `Network Analysis, Architecture, and Design' is about applying a systems methodology approach towards network design \cite{mccabe2010network}. McCabe's approach consists out of three core phases (figure \ref{fig:mccabe-process}); analysis, architecture and design. These simple, yet important planning phases in McCabe describe how to make technology and topology decisions in a network, especially for large deployments. These decisions are guided based on inputs for these three core phases, the initial input may be from users and/or from network metrics. Consecutive processes use the output of previous processes as input, thus these processes are interconnected.

\begin{figure}[H]
\centering
\includegraphics[width=\columnwidth]{images/mccabe-process.png}
\caption{Cyclic and iterative nature of McCabe's processes and phases.}
\label{fig:mccabe-process}
\end{figure}

% We need more space, this part can be left out without affecting the context
% In figure \ref{fig:mccabe-process} the three core phases are illustrated in \textit{italic} while the processes are in normal text. In order to highlight the core phases by name they are \underline{underlined} in the figure. The first phase (analysis) has as goal to understand the network and potential problems in terms of performance and efficiency in order to determine network requirements. This is done by developing sets of problem statements and objectives that describe what the target network should address. Therefore, historical data from network management (monitoring), requirements gathered from the network users, staff and management are included in the analysis phase. Furthermore, these metrics are then compared to the relationships between users, applications, devices and other networks in order to determine if requirements match with the user and network expectations. The second and third phase (architecture and design) uses the output of the first phase to establish a high-level design of the network. This network design determines which technology and topology choices are justified to improve the network requirements established in the first phase. The fourth process is implementing the design, test if requirements are met and finally accept the implementation. These phases are intended to be iterative and by no means define a final architecture design. This is due to the fact that requirements, technology and user behavior can change and with that the network design.

The following analysis provides a starting baseline for the high-level network design. As discussed in the related work section, several key scalability and performance metrics were addressed. It was concluded that TCP provided the most satisfying performance when compared to UDP. Furthermore, there are several \gls{ndn} strategies to choose from. The `leave copy everywhere' cache decision strategy and the `least recently used' cache replacement strategy were considered to be the overall best performing choices. However, for the forward strategies there was no decisive conclusion on which a selection could be based on. Therefore, we will use the default forwarding strategy; best-route. In terms of cache size, Koulouzis et al. recommends a cache size twice the size of the largest digital object residing in the used repositories \cite{koulouzis2018information}. The data catalogue or registry system provides metadata of digital objects, where the size and \gls{pid} type is available. This information may be used to sort the files in the (research Cloud) catalogue by maximum size. The performance configurations mentioned can be configured in the \texttt{nfd.conf} file of the \gls{cxx} application. \gls{cxx} is one of the most mature software implementations of \gls{ndn} and therefore used in our design. Other performance optimization solutions which were mentioned in the related work section require changes in the source-code. These source-code optimizations were not made public or are not yet integrated in existing software and therefore were not used.

\subsubsection{NFV}
Kubernetes can be used to automate container deployment, scaling, and management of containers. In Kubernetes a container is called a pod, this may be a Docker container. These Kubernetes pods can be deployed in a cluster of Kubernetes nodes, spanning over e.g. different data centers. This offers great flexibility by packaging an application in a pod and then scale the application in or out through different data centers with Kubernetes.

A requirement is flexible scalability, this will be addressed by deploying and managing \gls{ndn} in an \gls{nfv}-style. Therefore, \gls{ndn} will be deployed as virtual functions and managed centrally via Kubernetes. \gls{nfv} is a network architecture concept which uses virtualization to create and manage higher level network functions, as software, on commodity hardware. These functions may be interconnected to create a network service such as load-balancers, firewalls or intrusion detection. This architecture differs from traditional network architectures, where network functions are provided by hardware devices. \gls{nfv} provides the ability to easily duplicate network functionality and expand the network locally or into other data centers. \gls{nfv} is usually managed by an orchestrator to automate deployment, thus providing less overhead than traditional network management with hardware devices.

\begin{figure}[H]
\centering
\includegraphics[width=\columnwidth]{images/high-level-network-design.png}
\caption{High-level network design.}
\label{fig:high-level-network-design}
\end{figure}

\begin{figure*}[ht]
\centering
\includegraphics[width=\textwidth]{images/tosca-diagram.png}
\caption{TOSCA diagram.}
\label{fig:tosca-diagram}
\end{figure*}

Virtualization allows for flexible allocation of Cloud resources via VMs while scalability of software applications can be realized by the use of containers in a \gls{nfv}-style. If more Cloud resources are required, then this can be done by deploying more VMs. Furthermore, if needed, VMs can be deployed in specific geographically located Cloud providers, expanding the data distribution availability. The virtual \gls{ndn} functions running inside these Cloud providers, can then provide locally cached copies of digital objects. And thus providing data distribution which lowers the chance of network congestion. In figure \ref{fig:high-level-network-design} we illustrate our high-level network design. In this illustration there are two conceptual Cloud providers; `mulhouse' and `nimes'. These two nodes each are equipped with 12GB RAM and an Intel Xeon CPU E3-1240L v5 @ 2.10GHz with 1TB disks. In both of these conceptual Cloud providers a VM will be deployed in order to allocate the resources needed.


\subsubsection{TOSCA}
The heterogeneous nature in Cloud environments can make deployment automation and management complicated. \gls{tosca} is a method to describe the deployment and management of a Cloud infrastructure based on reusable templates \cite{tosca-standard}. These descriptions are then used by orchestrators to facilitate the deployment. SeaClouds (\gls{fp7} funded project), not to be confused with SeaDataNet, is a research Cloud that already manages infrastructures based on \gls{tosca} \footnote{\url{http://www.seaclouds-project.eu/}}. Brogi et al. concluded that SeaClouds can now realize their multiple Cloud infrastructures in an automated arrangement with central coordination, deployment and management without the need to make custom deployment strategies for each Cloud environment \cite{brogi2015adaptive}. Furthermore, several large companies such as Google, Red Hat, Canonical and IBM are also involved with the development of TOSCA, signifying that broader adoption may follow in the future.

\gls{drip} is currently a TOSCA-compatible prototype which uses the open Cloud computing interface and currently supports EC2, \gls{egi} FedCloud and \gls{exogeni} Clouds. Furthermore, \gls{drip} also supports Ansible playbooks for configuration management and contains a deployment agent for e.g. Kubernetes. This results into a portable (can be run by any orchestrator that understands TOSCA) and automated method (implementation carried out by an orchestrator) of infrastructure management. This allows interoperability and reusability of \gls{tosca} template descriptions on different Cloud providers. Reusability of templates is made possible by using variables to substitute e.g. IPs or hostnames. These variables can be retrieved with the `get\_attribute' function and can be declared by a reference node or relationship template.

TOSCA template descriptions consist out of the following core components; nodes, relationships and interfaces. Nodes can be a host, container or VM and are connected to each other through relationships such as `dependsOn', `hostedOn' and `connectsTo'. These relationships can be used to describe that a VM is `hosted on' a host (e.g. a bare metal machine). Or that a set of containers 'depend on' each other for functionality and 'connect to' e.g. a database. Such as a containerized web application that requires a database, facilitated by another container. Interfaces are used to control the life cycle of a component and consist as a set of hooks to trigger actions, these actions are create, configure, start, stop or delete. These hooks can be triggered to e.g. configure and create containers, stop or start a service or do system maintenance such as delete artifacts after a service is stopped. Furthermore, constraints can be set for the input values in these template descriptions. These can be e.g. that the amount of CPU's should be defined with integers and should contain a value more than one. However, the orchestrator is responsible for verifying these constraints, \gls{tosca} is merely a means to describe components in an infrastructure.

In figure \ref{fig:tosca-diagram}, a \gls{tosca} diagram is illustrated. This diagram represents an abstract template description of the \gls{tosca} relationships, in which the grey rectangular boxes are the core scalability factors. \gls{tosca} consists out of several types; nodes, relationships and interfaces. The scaling properties are highlighted in the rectangular areas. The left area, highlighted as `scaling in/out resources' contains a dependency chain of several virtual \gls{ndn} functions. This dependency chain is also depicted numerically.

Before a pod can be deployed on Kubernetes (step 2 to 5), a VM needs to exist (step 1). This is described by the `dependsOn' relationship. Furthermore, with the requirements defined, input constraints are described. These constraints are used by the orchestrator to make sure that the \gls{ndn} infrastructure has sufficient resources available to operate. Once a VM is deployed, the dependency for Kubernetes is satisfied, thus Kubernetes can then be setup (step 2). Kubernetes can then deploy pods by the use of interfaces (step 3). These interfaces feed the containers with environment variables such as the gateway, a list of routes, the transport protocol for \gls{ndn}, the \gls{ndn} strategies and on which Kubernetes node this pod should run. The environment variables are given to the interface via the \gls{tosca} inputs. These environment variables are then used by scripts that run inside the pods to setup \gls{ndn}. Several constraints are set for these environment variables such as which valid transport protocols can be used for \gls{ndn}, which \gls{ndn} strategies are valid and which nodes are available. These constraints are defined with e.g. `valid\_values' or `greater\_than' definitions. These constraints help to guide the orchestrator to verify the inputs that are given for the template description. As illustrated in the second gray area `scaling in/out the application', several pods can be instantiated (step 5a, 5b and 5c) from the image (step 4). These pods enable the virtual \gls{ndn} functions. These pods establish the \gls{ndn} and therefore are connected via the `connectsTo' relationship. This network expands over to other Kubernetes nodes in the cluster by the use of the Kubernetes built-in overlay network.

\subsection{NDN deployment as NFV}
% add sed command to substitute config lines in nfd.conf
The orchestrators mentioned when combined with a \gls{tosca} parser are still in a prototype phase. Therefore, in our prototype we deployed the VMs and Kubernetes nodes manually. In practice the life cycle of also the Kubernetes pods are managed by a \gls{tosca} orchestrator. Without having a \gls{tosca}-ready orchestrator available, steps 2 through 5 in figure \ref{fig:tosca-diagram} were be carried out by Kubernetes exclusively. This was done by defining the configuration properties of the pods manually\footnote{\url{https://github.com/AquaL1te/rp2/blob/master/Kubernetes/expanded-cluster.yml}}. These properties include the \gls{ndn} function name, e.g. router, producer or consumer. And also includes the routes (\gls{ndn} prefixes) and the associated \gls{ndn} face with the transport protocol to use (TCP or UDP). These parameters were then inserted into the \gls{ndn} \gls{fib} by the scripts that were executed inside the pod\footnote{\url{https://github.com/AquaL1te/rp2/blob/master/Docker/producer/docker-entrypoint.sh}}. The \gls{ndn} strategies were also configured by these scripts.

Furthermore, if it is not defined where a pod should be running, Kubernetes will make this decision itself, based on the known resources in the Kubernetes cluster. If for example a Kubernetes node has more memory to spare than other nodes, then Kubernetes will likely decide to spawn the pod there. This Kubernetes node could potentially run in a Cloud provider located in another geographical area. Since the purpose is to provide data distribution through the use of \gls{ndn}, locality becomes a key factor. Therefore, a pod is specifically assigned to a Kubernetes node in order to provide in-network caching in a specific geographical area.

The methods discussed offer a combined way to plan and deploy a data distribution network. McCabe can be used to methodologically establish the performance requirements. \gls{tosca} can be used to apply these performance requirements to the virtualized environment from a central deployment and management description. For the size of this prototype the McCabe method is extra overhead. However, the prototype is only used to demonstrate the train of thought. The methods discussed can be applied to larger deployments where the McCabe method will be more valuable.

In conclusion, the \gls{pid} to \gls{ndn} name translation prototype (section \ref{interoperablity}) is integrated as \gls{nfv} pods in our deployment prototype. This enables flexible scaling by the use of Cloud providers.

\section{Discussion, conclusion and future work}
Where traditionally IP is used for host-to-host communication, our prototype utilizes \gls{ndn}. Lim et al. researched and proved the effectiveness of \gls{ndn} for big science workflows. However, the data distribution benefits provided by \gls{ndn} would become unscalable without the means to flexibly maintain the life cycle of such an infrastructure. The prototype we researched and developed offers the means to plan and manage the \gls{ndn} life cycle on a larger scale by utilizing Cloud providers. In contrast, if \gls{ndn} was deployed without the discussed planning and deployment methods, an alternative would then be to have custom non-centrally managed deployments for each Cloud environment. Which may create inconsistent deployments and errors. Although such an non-central approach also realizes a data distribution network by the use of \gls{ndn}, it does not scale as well in terms of deployment and management.

The McCabe method is utilized to establish the requirements and high-level design of the \gls{ndn} in TOSCA \cite{mccabe2010network}. McCabe offers a proven, yet simple methodological approach for defining the design goals, which are then used to define the \gls{tosca} descriptions. By using the \gls{tosca} standard, deployments in \gls{tosca}-ready Cloud providers are possible with a uniform deployment description. This flexibility allows the data distribution network to scale easily and make management uncomplicated. However, \gls{tosca}-ready Cloud providers are still rare, for our prototype to be more relevant, a wider adoption is needed.

% Due to the nature of Kubernetes, pods are deployed based on the resource requirements of a pod and the resource availability inside a cluster. Pods that run \gls{ndn} functions are not only interested in Kubernetes resources, but their true value is mainly determined on locality. This is due to the distributed nature of \gls{ndn}, which depends on in-network caching along the network path between data producers and consumers. If Kubernetes does not deploy a pod where \gls{ndn} resources are needed, then human intervention is needed to specify on which Kubernetes node a pod must run. Therefore, if Kubernetes could be extended with the intelligence of also \gls{ndn}'s resource needs, it could deploy pods automatically in a certain geographical area in order to increase cache hits.

Furthermore, the \gls{ndn} faces were configured manually, this was due to the lack of mature \gls{ndn} routing protocols. However there are two promising routing protocols in development; \gls{ospfn} by Lan Wang et. al. \cite{ndn-ospfn2} and \gls{nlsr} \cite{nlsr}. With a routing protocol, the \gls{ndn} management process would become less complicated and more resilient.

Furthermore, in research Clouds identification services are used and utilize different \gls{pid} schemas. Our prototype offers a better integration between the identification and the data transmission services. However, our prototype exists outside of the \gls{ndn} source code. For the best application of this functionality, we recommend the integration of these interoperability functionalities into the native \gls{ndn} source code. This would remove the need to run a translation gateway.

Research Clouds are in general a federated Cloud, where each federation is responsible for its own budget and infrastructure. However, our prototype assumes central control over the \gls{ndn}. Our prototype could be approached in several ways. The discussed solutions could be deployed as an internal data-sharing platform per infrastructure and interconnect those \gls{ndn}'s, thus maintaining the federated model. Or, it could be deployed as a third party data-sharing platform, where one can deploy and operate the \gls{ndn} for multiple infrastructures. Our research did not explore these subjects. However, it provides the flexibility to deploy these solutions in such a manner.

\section*{Acknowledgment}
We would like to thank Dr. Zhiming Zhao for his supervision and advice during this research. This paper is largely based on the work done by Kees de Jong, MSc and Anas Younis, MSc \cite{de2019planning}.
% how to acknoledge cas? his poster is not published (google scholar)

% \section*{References}
\newacronym{pid}{PID}{Persistent Identifier}
\newacronym{eosc}{EOSC}{European Open Science Cloud}
\newacronym{ndn}{NDN}{Named Data Networking}
\newacronym{icn}{ICN}{Information Centric Networking}
\newacronym{cmmap}{CMMAP}{Center for Multiscale Modeling of Atmospheric Processes}
\newacronym{cmip}{CMIP5}{Coupled Model Intercomparison Project}
\newacronym{uri}{URI}{Uniform Resource Identifier}
\newacronym{url}{URL}{Uniform Resource Locator}
\newacronym{urn}{URN}{Uniform Resource Name}
\newacronym{doi}{DOI}{Digital Object Identifier}
\newacronym{purl}{PURL}{Persistent Uniform Resource Locator}
\newacronym{ark}{ARK}{Archival Resource Key}
\newacronym{tosca}{TOSCA}{Topology and Orchestration Specification for Cloud Applications}
\newacronym{drip}{DRIP}{Dynamic Real-time Infrastructure Planner}
\newacronym{cnri}{CNRI}{Corporation for National Research Initiatives}
\newacronym{fib}{FIB}{Forwarding Information Base}
\newacronym{pit}{PIT}{Pending Interest Table}
\newacronym{cs}{CS}{Content Store}
\newacronym{n2t}{N2T}{Names to Things}
\newacronym{ospfn}{OSPFN}{Open Shortest Path First for NDN}
\newacronym{ghr}{GHR}{Global Handle Registry}
\newacronym{ghs}{GHS}{Global Handle System}
\newacronym{dtr}{DTR}{Data Type Registry}
\newacronym{ra}{RA}{Registration Authority}
\newacronym{idf}{IDF}{International DOI Foundation}
\newacronym{nlsr}{NLSR}{Named-data Link State Routing}
\newacronym{cs3}{CS3}{Cloud Storage Synchronization and Sharing Services}
\newacronym{cdn}{CDN}{Content Delivery Network}
\newacronym{nfv}{NFV}{Network Functions Virtualization}
\newacronym{isbn}{ISBN}{International Standard Book Number}
\newacronym{gpl}{GPLv3}{General Public License}
\newacronym{ddos}{DDoS}{Distributed Denial of Service}
\newacronym{naas4pid}{NaaS4PID}{NDN-as-a-service for PID data objects}
\newacronym{cxx}{NDN-CXX}{NDN C++ library with eXperimental eXtensions}
\newacronym{ccnx}{CCNx}{Content-Centric Networking}
\newacronym{rfc}{RFC}{Request for Comments}
\newacronym{dona}{DONA}{Digital Object Numbering Authority}
\newacronym{ucs}{UCS}{Universal Coded Character Set}
\newacronym{rdf}{RDF}{Resource Description Framework}
\newacronym{oasis}{OASIS}{Organization for the Advancement of Structured Information Standards}
\newacronym{egi}{EGI}{European Grid Infrastructure}
\newacronym{exogeni}{ExoGENI}{Exo Global Environment for Network Innovation}
\newacronym{fp7}{EU FP7}{European Seventh Framework Programme}
\newacronym{do}{DO}{Digital Object}
\newacronym{dcx}{DCX}{Dublin Core}
\newacronym{anp}{ANP}{Algemeen Nederlands Persbureau}
\newacronym{nr}{NR}{National Resolver}
\newacronym{ir}{IR}{Institutional Repository}
\newacronym{doip}{DOIP}{Digital Object Interface Protocol}
\newacronym{fairness}{FAIRness}{Findability, Accessibility, Interoperability and Re-usability}
\newacronym{icos}{ICOS}{Integrated Carbon Observation System Research Infrastructure}
\newacronym{ri}{RI}{Research Infrastructure}
\newacronym{actris}{ACTRIS}{Aerosol, Clouds and Trace Gases}
\newacronym{epos}{EPOS}{European Plate Observing System}
\newacronym{envri}{ENVRI-FAIR}{ENVironmental Research Infrastructures building Fair services Accessible for society, Innovation and Research}
\newacronym{rda}{RDA}{Research Data Alliance}
\newacronym{sdn}{SDN}{Software Defined Networking}


\bibliographystyle{./bibliography/IEEEtran}
\bibliography{./bibliography/IEEEabrv,./bibliography/IEEEexample}

\end{document}